x-environment:
  &shared-environment # Pass to build environments and containers for all services
  API_DOMAIN: &api-domain ""
  APP_DOMAIN: &app-domain ""
  APP_TITLE: &app-title "Architecture Identifier"
  APP_DESCRIPTION: &app-description "Identify architectural style of buildings with machine learning"
  APP_GITHUB_URL: &app-github-url ""
  APP_AUTHOR_NAME: &author-name "Gary Tyler"
  APP_AUTHOR_URL: &author-url "https://github.com/garytyler"

    
services:
  frontend:
    container_name: frontend
    build:
      context: ./frontend
      target: production
    environment:
      REACT_APP_API_DOMAIN: *api-domain      
      REACT_APP_APP_DOMAIN: *app-domain
      REACT_APP_APP_TITLE: *app-title
      REACT_APP_APP_DESCRIPTION: *app-description
      REACT_APP_APP_GITHUB_URL: *app-github-url
      REACT_APP_AUTHOR_NAME: *author-name
      REACT_APP_AUTHOR_URL: *author-url
    ports:
      - 3000:3000

  backend:
    container_name: backend
    environment:
      POETRY_VERSION: 1.1.11
    build:
      context: ./backend
      target: production
    command:
      [
        "gunicorn",
        "-k",
        "uvicorn.workers.UvicornWorker",
        "-c",
        "./gunicorn_conf.py",
        "app.main:app",
      ]
    ports:
      - 8000:8000
    links:
      - models
    volumes:
      - ./backend:/srv/backend

  models:
    container_name: models
    image: tensorflow/serving:latest
    ports:
      - 8500:8500
      - 8501:8501
    command:
      - --model_config_file=/config/models.prod.config
      - --model_config_file_poll_wait_seconds=300
      - --rest_api_timeout_in_ms=30000
      # - --enable_batching=true
      # - --batching_parameters_file=/config/batching_parameters.txt
      # - --monitoring_config_file=/config/monitoring_config.txt
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_REGION=${AWS_REGION}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_ENDPOINT=${S3_ENDPOINT}
    volumes:
      - ./config:/config

  # models:
  #   container_name: models
  #   image: tensorflow/serving:latest-gpu
  #   ports:
  #     - 8501:8501
  #   environment:
  #     - MODEL_BASE_PATH=/models
  #     - MODEL_NAME=InceptionResNetV2-imagenet
  #   volumes:
  #     - ./models:/models

  # train:
  #   ports:
  #     - 6006:6006
  #   volumes:
  #     - .:/srv:rw"
  #     - ${DATASET_DIR:-./dataset}:/dataset:ro
  #     - ${OUTPUT_DIR:-./output}:/output

volumes:
  postgres_data: null
